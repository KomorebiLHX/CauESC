# CauESC
This is the repository of CauESC: A Causal Aware Model for Emotional Support Conversation.

You can use the repo to reproduce experimental results or apply CauESC to other datasets.

The source code is based on [thu-coai/Emotional-Support-Conversation: Data and codes for ACL 2021 paper: Towards Emotional Support Dialog Systems (github.com)](https://github.com/thu-coai/Emotional-Support-Conversation), especially the code from [Chujie Zheng](https://github.com/chujiezheng). Thank relevant researchers for their past work.

## Preparing Enviroment

Firstly, download the environment file from [here](https://1drv.ms/u/s!As-JDklAqWxfjid1ultOpucz1xxq?e=bKKDg3).

After that, execute the following command to activate the environment:

```shell
cd ~
mkdir cuda11.6
tar -xzf cuda11.6.tar.gz -C cuda11.6
source cuda11.6/bin/activate
```

## Downloading Dataset

CauESC not only requires ESConv, but also COMET's commonsense representation and emotion cause annotation. Therefore, please download the relevant dataset files from [here](https://1drv.ms/f/s!As-JDklAqWxfjihV_rMoTCQgOOR7?e=lv74cz) and place it in the `_reformat`.

To indicate the source, the method for obtaining common sense representations originates from [conv-emotion/COSMIC/feature-extraction at master · declare-lab/conv-emotion (github.com)](https://github.com/declare-lab/conv-emotion/tree/master/COSMIC/feature-extraction). Moreover, the method of tecognizing rmotion vause originates from [declare-lab/RECCON: This repository contains the dataset and the PyTorch implementations of the models from the paper Recognizing Emotion Cause in Conversations. (github.com)](https://github.com/declare-lab/RECCON).

## Downloading Model

You should first download the [BlenderBot-small](https://huggingface.co/facebook/blenderbot_small-90M) model and put  `pytorch_model.bin` file in `Blenderbot_small-90M`.

You can also download the [DialoGPT](https://huggingface.co/microsoft/DialoGPT-small?text=Hey+my+name+is+Thomas%21+How+are+you%3F) model and  put  `pytorch_model.bin` file in `DialoGPT-small`.

If you would like to evaluate generated results with Embedding-based similarity, you can download my prepared embedding files from [here](https://1drv.ms/u/s!As-JDklAqWxfjiQmi34EfY_eCKFh?e=AOYEci).

## About Postfix

- `_vanilla` denotes the variant directly fine-tuned on ESConv without using strategies.
- `_strat` denotes the one that additionally uses the strategy information and supervision.
- `_comet` denotes CauESC that causally uses emotion causes and emotion effects information.

## Preprocessing Training Data

Firstly, enter `_reformat` and run `python process.py`.

Then, run `bash scripts/prepare_comet.sh` to preprocess the training data.

## Training Your Model

Run `bash scripts/train_comet.sh {CUDA_VISIBLE_DEVICES}` to train your model.

## Inference with Your Model

Every time of model training will create a new folder in `DATA/{inputter_name}.{config_name}`, which is named after the time when the training starts. You should select a checkpoint (it may be based on the PPL of validation), and replace the checkpoint path in `scripts/infer_comet.sh` with the path of your selected checkpoint. If you want to **reproduce experimental results**, you can download the best checkpoint from [here](https://1drv.ms/u/s!As-JDklAqWxfjh-nGmYzItCSL3zt?e=y9vga3) and replace the checkpoint path in `scripts/infer_comet.sh` with the path of downloaded checkpoint.

Then, run `bash scripts/infer_comet.sh {CUDA_VISIBLE_DEVICES}` to do the inference.

## Generation from CauESC

The responses and the metrics generated by CauESC is saved in `cauesc_result`. You can use the folder for automatic evaluation and manual evaluation, and **automatic evaluation** can be used as follows.

| Model            |  ACC(%)↑  |   PPL↓    |   R-L↑    |   B-2↑   |   B-3↑   |   B-4↑   |   D-1↑   |   D-2↑    |
| :--------------- | :-------: | :-------: | :-------: | :------: | :------: | :------: | :------: | :-------: |
| Transformer      |     -     |  114.75   |   14.64   |   6.20   |   3.07   |   1.85   |   0.13   |   0.28    |
| MT Transformer   |     -     |  109.44   |   14.94   |   5.99   |   2.60   |   1.37   |   0.15   |   0.35    |
| MoEL             |     -     |   57.03   |   13.93   |   5.48   |   2.40   |   1.25   |   0.74   |   4.12    |
| MIME             |     -     |   56.06   |   14.66   |   6.35   |   2.72   |   1.36   |   0.91   |   5.17    |
| DialoGPT-Joint   |   24.20   |   20.79   |   14.36   |   5.76   |   2.81   |   1.67   |   2.41   |   15.17   |
| Blenderbot-Joint |   31.17   |   18.60   |   17.03   |   5.80   |   3.09   |   1.88   |   3.08   |   13.95   |
| MISC             |   31.63   |   16.16   |   17.91   |   7.31   |   3.78   |   2.20   |   4.41   |   19.71   |
| CauESC           | **33.33** | **15.30** | **18.20** | **8.17** | **4.55** | **2.82** | **4.70** | **19.85** |

## Citation

If this work is helpful, please kindly cite as:
```bibtex
@misc{chen2024cauesccausalawaremodel,
title={CauESC: A Causal Aware Model for Emotional Support Conversation}, 
author={Wei Chen and Hengxu Lin and Qun Zhang and Xiaojin Zhang and Xiang Bai and Xuanjing Huang and Zhongyu Wei},
year={2024},
eprint={2401.17755},
archivePrefix={arXiv},
primaryClass={cs.CL},
url={https://arxiv.org/abs/2401.17755}, 
}
```